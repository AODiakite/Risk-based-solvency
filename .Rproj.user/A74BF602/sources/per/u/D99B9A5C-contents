# Charger les packages nécessaires
library(rvest)
library(dplyr)
library(lubridate)
library(keras)

# Définir l'URL de la page web à scraper
url <- "Moroccan All Shares - Données Historiques.csv"
masi_data = read.csv(url)
# Extraire le tableau des données historiques de l'indice MASI
masi_data <- url %>%
  read_html() %>%
  html_nodes(xpath = '//*[@id="historique"]/table') %>%
  html_table() %>%
  .[[1]]

# Convertir les colonnes en format numérique et date
masi_data <- masi_data %>%
  mutate(
    Date = dmy(Date),
    Ouverture = as.numeric(gsub(",", ".", Ouverture)),
    Plus.haut = as.numeric(gsub(",", ".", Plus.haut)),
    Plus.bas = as.numeric(gsub(",", ".", Plus.bas)),
    Clôture = as.numeric(gsub(",", ".", Clôture)),
    Variation = as.numeric(gsub(",", ".", Variation)),
    Volume = as.numeric(gsub(",", "", Volume))
  )

# Afficher les premières lignes du tableau
head(masi_data)


# Sélectionner la colonne Clôture comme variable cible
y <- masi_data$Clôture

# Normaliser les données entre 0 et 1
y_min <- min(y)
y_max <- max(y)
y_norm <- (y - y_min) / (y_max - y_min)

# Définir la taille de la fenêtre temporelle
window_size <- 10

# Créer des séquences de données avec la fenêtre temporelle
x <- NULL
for (i in seq(window_size, length(y_norm))) {
  x <- rbind(x, y_norm[(i - window_size + 1):i])
}

# Séparer les données en entraînement (80%) et test (20%)
train_size <- floor(0.8 * nrow(x))
x_train <- x[1:train_size, ]
x_test <- x[(train_size + 1):nrow(x), ]
y_train <- y_norm[(window_size + 1):(window_size + train_size)]
y_test <- y_norm[(window_size + train_size + 1):length(y_norm)]

# Redimensionner les données pour le modèle RNN
x_train <- array(x_train, dim = c(nrow(x_train), window_size, 1))
x_test <- array(x_test, dim = c(nrow(x_test), window_size, 1))


# Définir le modèle RNN avec une couche LSTM et une couche Dense
model <- keras_model_sequential() %>%
  layer_lstm(units = 32, input_shape = c(window_size, 1)) %>%
  layer_dense(units = 1)

# Compiler le modèle avec une fonction de perte MSE et un optimiseur Adam
model %>% compile(
  loss = "mean_squared_error",
  optimizer = optimizer_adam(lr = 0.001)
)

# Entraîner le modèle sur les données d'entraînement pendant 50 époques
history <- model %>% fit(
  x_train,
  y_train,
  epochs = 50,
  batch_size = 32,
  validation_split = 0.2,
  verbose = 2
)


# Calculer la perte MSE sur les données de test
mse_test <- model %>% evaluate(x_test, y_test)
cat("MSE sur les données de test:", mse_test, "\n")

# Faire des prédictions sur les données de test
y_pred <- model %>% predict(x_test)

# Dénormaliser les prédictions et les valeurs réelles
y_pred <- y_pred * (y_max - y_min) + y_min
y_test <- y_test * (y_max - y_min) + y_min

# Tracer les prédictions et les valeurs réelles sur un graphique
plot(y_test, type = "l", col = "blue", main = "Prédictions du modèle RNN sur l'indice MASI",
     xlab = "Temps", ylab = "Cours de clôture")
lines(y_pred, col = "red")
legend("topleft", legend = c("Réel", "Prédit"), col = c("blue", "red"), lty = 1)

