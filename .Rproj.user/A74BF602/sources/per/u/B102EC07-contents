from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd

def scrape_data(url, start_date, end_date, browser='Chrome'):
    # Créer une instance de navigateur
    if browser == 'Firefox':
        driver = webdriver.Firefox()
    elif browser == 'Chrome':
        driver = webdriver.Chrome()
    else:
        raise ValueError(f"Unsupported browser: {browser}")

    # Accéder à l'URL de base
    driver.get(url)

    # Sélectionner les dates de début et de fin
    date_start_input = driver.find_element(By.CSS_SELECTOR, '#date_from')
    date_start_input.clear()
    date_start_input.send_keys(start_date)
    date_end_input = driver.find_element(By.CSS_SELECTOR, '#date_to')
    date_end_input.clear()
    date_end_input.send_keys(end_date)

    # Cliquer sur le bouton "Chercher"
    search_button = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div/div/div[1]/div[3]/div[1]/input[3]')
    

    # Attendre que la table des données soit chargée
    table = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, 'table'))
    )

    # Extraire les données de la table
    headers = [th.text.strip() for th in table.find_elements(By.CSS_SELECTOR, 'tr th')]
    data = []
    for row in table.find_elements(By.CSS_SELECTOR, 'tr')[1:]:
        values = [td.text.strip() for td in row.find_elements(By.CSS_SELECTOR, 'td')]
        data.append(dict(zip(headers, values)))

    # Créer une DataFrame Pandas à partir des données
    df = pd.DataFrame(data)

    # Fermer le navigateur
    driver.quit()

    return df

# Exemple d'utilisation de la fonction
url = "https://medias24.com/leboursier/fiche-action?action=alliances-p&valeur=historiques"
start_date = "01/01/2022"
end_date = "31/12/2022"
browser = "Chrome"
data = scrape_data(url, start_date, end_date, browser)
print(data)
